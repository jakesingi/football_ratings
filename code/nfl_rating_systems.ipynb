{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# 2021 NFL Team Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jakesingleton/Documents/projects/football/code'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from functools import reduce\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "We will implement the Massey and Colley methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### 0. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Loads data from nfl_game_data.ipynb to a data frame\n",
    "def load_data(year):\n",
    "    return pd.read_csv(\"../data/\" + str(year) + \"_nfl_game_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### 1. Massey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Massey method\n",
    "\n",
    "# get_massey() takes a data frame df, runs the Massey algorithm, and returns the Massey Matrix M and the results\n",
    "# REQUIRED: columns called \"Home Team\", \"Away Team\", \"Home Score\", \"Away Score\", and \"Margin\"\n",
    "# (Margin is defined by Home Score - Away Score)\n",
    "def get_massey(df):\n",
    "    # Build M\n",
    "    # Get games played for each team\n",
    "    diag = df['Home Team'].value_counts().append(df[\"Away Team\"].value_counts())\n",
    "    diag = diag.groupby(diag.index).sum()\n",
    "    M = pd.DataFrame(np.diag(diag), index = diag.index, columns = diag.index)\n",
    "    for team in M.index:\n",
    "        sub_df = df[(df[\"Home Team\"] == team) | (df[\"Away Team\"] == team)].reset_index()\n",
    "        for i in range(sub_df.shape[0]):\n",
    "            if sub_df.at[i, \"Home Team\"] == team:\n",
    "                opp = sub_df.at[i, \"Away Team\"]\n",
    "            else:\n",
    "                opp = sub_df.at[i, \"Home Team\"]\n",
    "            M.at[team, opp] = M.at[team, opp] - 1\n",
    "    #print(M)\n",
    "    # Build point differential vector p\n",
    "    df[\"Away Diff\"] = df[\"Away Score\"] - df[\"Home Score\"]\n",
    "    diff_home = df.groupby(\"Home Team\").agg({\"Margin\": \"sum\"})\n",
    "    diff_away = df.groupby(\"Away Team\").agg({\"Away Diff\": \"sum\"})\n",
    "    merged = diff_home.merge(diff_away, left_index = True, right_index = True, how = \"outer\").fillna(0)\n",
    "    merged[\"diff\"] = merged[\"Margin\"] + merged[\"Away Diff\"]\n",
    "    #print(merged)\n",
    "    p = np.array(merged[\"diff\"])\n",
    "    #print(p)\n",
    "    # Get M-bar and p-bar \n",
    "    Mbar = M.copy()\n",
    "    pbar = p.copy()\n",
    "    Mbar.iloc[Mbar.shape[0] - 1] = 1\n",
    "    pbar[-1] = 0\n",
    "    #print(Mbar, pbar)\n",
    "    # Ratings vector r\n",
    "    r = np.linalg.solve(Mbar, pbar)\n",
    "    # Results data frame\n",
    "    ratings = pd.DataFrame({\"Team\": Mbar.index, \"Rating\": r})\n",
    "    # Now obtain offensive and defensive rating vectors through clever algebra\n",
    "    # T is square diagonal matrix holding number of games played\n",
    "    T = np.identity(Mbar.shape[0])\n",
    "    np.fill_diagonal(T, np.diag(M))\n",
    "    #print(T)\n",
    "    # P is off-diagonal matrix holding number of games played between two teams\n",
    "    P = np.array(M.copy())\n",
    "    np.fill_diagonal(P, 0)\n",
    "    P = P * -1\n",
    "    #print(P)\n",
    "    # Points For vector f\n",
    "    f = (df.groupby(\"Home Team\").agg({\"Home Score\": \"sum\"})[\"Home Score\"]\n",
    "         .append(df.groupby(\"Away Team\").agg({\"Away Score\": \"sum\"})[\"Away Score\"]))\n",
    "    f = f.groupby(f.index).sum()\n",
    "    #print(f)\n",
    "    # Get defensive rating vector d\n",
    "    d = np.linalg.solve(T + P, T@r - f)\n",
    "    ratings[\"D Rating\"] = d\n",
    "    # Get offensive rating vector o\n",
    "    o = r - d\n",
    "    ratings[\"O Rating\"] = o\n",
    "    ratings = ratings[[\"Team\", \"Rating\", \"O Rating\", \"D Rating\"]]\n",
    "    ratings = ratings.sort_values(by = \"Rating\", ascending = False)\n",
    "    ratings[\"Rank\"] = ratings[\"Rating\"].rank(ascending = False)\n",
    "    # Return Massey Matrix M and ratings data frame \n",
    "    return M, ratings.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Home Team</th>\n",
       "      <th>Away Team</th>\n",
       "      <th>Home Score</th>\n",
       "      <th>Away Score</th>\n",
       "      <th>Margin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Duke</td>\n",
       "      <td>Miami</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>-45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Duke</td>\n",
       "      <td>UNC</td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Duke</td>\n",
       "      <td>UVA</td>\n",
       "      <td>7</td>\n",
       "      <td>38</td>\n",
       "      <td>-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Duke</td>\n",
       "      <td>VT</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>-45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Miami</td>\n",
       "      <td>UNC</td>\n",
       "      <td>34</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Miami</td>\n",
       "      <td>UVA</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Miami</td>\n",
       "      <td>VT</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>UNC</td>\n",
       "      <td>UVA</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>UNC</td>\n",
       "      <td>VT</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>UVA</td>\n",
       "      <td>VT</td>\n",
       "      <td>14</td>\n",
       "      <td>52</td>\n",
       "      <td>-38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Home Team Away Team  Home Score  Away Score  Margin\n",
       "0      Duke     Miami           7          52     -45\n",
       "1      Duke       UNC          21          24      -3\n",
       "2      Duke       UVA           7          38     -31\n",
       "3      Duke        VT           0          45     -45\n",
       "4     Miami       UNC          34          16      18\n",
       "5     Miami       UVA          25          17       8\n",
       "6     Miami        VT          27           7      20\n",
       "7       UNC       UVA           7           5       2\n",
       "8       UNC        VT           3          30     -27\n",
       "9       UVA        VT          14          52     -38"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teams = [\"Duke\", \"Miami\", \"UNC\", \"UVA\", \"VT\"]\n",
    "examp = pd.DataFrame(data = {\"Home Team\": [\"Duke\", \"Duke\", \"Duke\", \"Duke\", \"Miami\", \"Miami\", \"Miami\", \"UNC\", \"UNC\", \"UVA\"],\n",
    "                             \"Away Team\": [\"Miami\", \"UNC\", \"UVA\", \"VT\", \"UNC\", \"UVA\", \"VT\", \"UVA\", \"VT\", \"VT\"],\n",
    "                             \"Home Score\": [7, 21, 7, 0, 34, 25, 27, 7, 3, 14],\n",
    "                             \"Away Score\": [52, 24, 38, 45, 16, 17, 7, 5, 30, 52]})\n",
    "examp[\"Margin\"] = examp[\"Home Score\"] - examp[\"Away Score\"]\n",
    "examp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export examp \n",
    "examp.to_csv(\"../data/examp_data.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "      <th>O Rating</th>\n",
       "      <th>D Rating</th>\n",
       "      <th>Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Miami</td>\n",
       "      <td>18.2</td>\n",
       "      <td>21.975000</td>\n",
       "      <td>-3.775000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>VT</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.708333</td>\n",
       "      <td>-2.708333</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>UVA</td>\n",
       "      <td>-3.4</td>\n",
       "      <td>7.841667</td>\n",
       "      <td>-11.241667</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>UNC</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>1.375000</td>\n",
       "      <td>-9.375000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Duke</td>\n",
       "      <td>-24.8</td>\n",
       "      <td>1.975000</td>\n",
       "      <td>-26.775000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Team  Rating   O Rating   D Rating  Rank\n",
       "0  Miami    18.2  21.975000  -3.775000   1.0\n",
       "1     VT    18.0  20.708333  -2.708333   2.0\n",
       "2    UVA    -3.4   7.841667 -11.241667   3.0\n",
       "3    UNC    -8.0   1.375000  -9.375000   4.0\n",
       "4   Duke   -24.8   1.975000 -26.775000   5.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M_examp, ratings_examp = get_massey(examp)\n",
    "ratings_examp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a nice example to verify with the book! Exactly right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Colley "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Colley method\n",
    "\n",
    "# get_colley() takes a data frame of df and the Massey Matrix M, runs the Colley algorithm, and returns the Colley Matrix C and the results\n",
    "# REQUIRED: data frame like one for get_massey() and the outputs from get_massey()\n",
    "def get_colley(df, M):\n",
    "    # We can use the identity on Who's #1? page 24 to easily get the Colley Matrix C\n",
    "    C = 2 * np.identity(M.shape[0]) + M\n",
    "    # Get Win/Loss data\n",
    "    df[\"Winner\"] = np.where(df[\"Margin\"] > 0, df[\"Home Team\"], df[\"Away Team\"])\n",
    "    df[\"Loser\"] = np.where(df[\"Margin\"] > 0, df[\"Away Team\"], df[\"Home Team\"])\n",
    "    wins = df.groupby(\"Winner\").count()[\"Loser\"]\n",
    "    losses = df.groupby(\"Loser\").count()[\"Winner\"]\n",
    "    teams = sorted(set(df[[\"Winner\", \"Loser\"]].values.flatten()))\n",
    "    w_l_dict = {}\n",
    "    for team in teams:\n",
    "        if team not in losses.index:\n",
    "            w_l_dict[team] = wins[team] - 0\n",
    "        elif team not in wins.index:\n",
    "            w_l_dict[team] = 0 - losses[team]\n",
    "        else:\n",
    "            w_l_dict[team] = wins[team] - losses[team]\n",
    "    # Get vector b for Colley algorithm\n",
    "    w_l_diff = np.fromiter(w_l_dict.values(), dtype = float)\n",
    "    b = 1 + 0.5 * w_l_diff\n",
    "    # Results data frame\n",
    "    r = np.linalg.solve(C, b)\n",
    "    ratings = pd.DataFrame({\"Team\": teams, \"Rating\": r}).sort_values(by = \"Rating\", ascending = False)\n",
    "    ratings[\"Rank\"] = ratings[\"Rating\"].rank(ascending = False)\n",
    "    # Return Colley Matrix C and ratings data frame \n",
    "    return C, ratings.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Miami</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>VT</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>UNC</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>UVA</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Duke</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Team    Rating  Rank\n",
       "0  Miami  0.785714   1.0\n",
       "1     VT  0.642857   2.0\n",
       "2    UNC  0.500000   3.0\n",
       "3    UVA  0.357143   4.0\n",
       "4   Duke  0.214286   5.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_examp, examp_colley_ratings = get_colley(examp, M_examp)\n",
    "examp_colley_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect! Matches the book"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank Aggregation: Simulated Game Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each set of rankings, we can generate ${32 \\choose 2} = 496$ pairwise matchups. For our Massey rankings, we will compute point differentials for these hypothetical matchups using the Massey ratings themselves. This makes sense since this is the underlying assumption of the Massey algorithm. For our Colley rankings, we will compute point differentials by the difference in `Rank` position. Then we use a combiner method on this simulated game data to create one set of ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note that the `Home Team`, `Away Team`, etc. columns in the simulated game data are meaningless. They are there so that our algorithm will run and will not affect results.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have our simulated game data we make a subjective choice. In particular, we must apply a combiner method, which is just the name for a rating system. For now, I will re-apply Massey. Why? Because in the NFL, due to a relatively level playing field, point differential should better reflect team strength than wins and losses themselves. For CFB, I will probably employ Colley at this step, since you often see teams like Alabama brutally blow out the poor Citadel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "# get_sim_game_dat() is a helper function\n",
    "# Inputs: a rating list, rating method of choice, and losing score and generates simulated game data\n",
    "# Output: appropriate simulated game data to be used by a combiner method\n",
    "def get_sim_game_dat(rating_lst, method, losing_score):\n",
    "    # Get team combinations for simulated game data matchups\n",
    "    team_combos = list(combinations(rating_lst[\"Team\"], 2))\n",
    "    team1 = [matchup[0] for matchup in team_combos]\n",
    "    team2 = [matchup[1] for matchup in team_combos]\n",
    "    lst_sim_game_dat = (pd.DataFrame(data = {\"Home Team\": team1, \"Away Team\": team2})\n",
    "                        .merge(rating_lst, left_on = \"Home Team\", right_on = \"Team\")\n",
    "                        .merge(rating_lst, left_on = \"Away Team\", right_on = \"Team\", suffixes = (\"_Home\", \"_Away\"))\n",
    "                        .drop(columns = [\"Team_Home\", \"Team_Away\"]))\n",
    "    if method == \"Massey\":\n",
    "        lst_sim_game_dat[\"Home Score\"] = (np.where(lst_sim_game_dat[\"Rating_Home\"] > lst_sim_game_dat[\"Rating_Away\"],\n",
    "                                                     losing_score + \n",
    "                                                     np.floor(lst_sim_game_dat[\"Rating_Home\"] - \n",
    "                                                              lst_sim_game_dat[\"Rating_Away\"]),\n",
    "                                                     losing_score))\n",
    "        lst_sim_game_dat[\"Away Score\"] = (np.where(lst_sim_game_dat[\"Rating_Away\"] > lst_sim_game_dat[\"Rating_Home\"],\n",
    "                                                     losing_score + \n",
    "                                                     np.floor(lst_sim_game_dat[\"Rating_Away\"] - \n",
    "                                                              lst_sim_game_dat[\"Rating_Home\"]),\n",
    "                                                     losing_score))\n",
    "    elif method == \"Colley\":\n",
    "        lst_sim_game_dat[\"Home Score\"] = (np.where(lst_sim_game_dat[\"Rank_Home\"] < lst_sim_game_dat[\"Rank_Away\"],\n",
    "                                                     losing_score + \n",
    "                                                     np.floor(lst_sim_game_dat[\"Rank_Away\"] - \n",
    "                                                              lst_sim_game_dat[\"Rank_Home\"]),\n",
    "                                                     losing_score))\n",
    "        lst_sim_game_dat[\"Away Score\"] = (np.where(lst_sim_game_dat[\"Rank_Away\"] < lst_sim_game_dat[\"Rank_Home\"],\n",
    "                                                     losing_score + \n",
    "                                                     np.floor(lst_sim_game_dat[\"Rank_Home\"] - \n",
    "                                                              lst_sim_game_dat[\"Rank_Away\"]),\n",
    "                                                     losing_score))\n",
    "    else:\n",
    "        pass\n",
    "    lst_sim_game_dat[\"Margin\"] = lst_sim_game_dat[\"Home Score\"] - lst_sim_game_dat[\"Away Score\"]\n",
    "    return lst_sim_game_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate_lists() aggregates rating/ranking lists into one combind superior list\n",
    "# Inputs: df of standard game data, lsts of rating/ranking lists, combiner_method (rating algorithm of our choice)\n",
    "# Output: one superior rating/ranking list\n",
    "def aggregate_lists(df, lsts, combiner_method):\n",
    "    # Average losing score for simulated game data\n",
    "    losing_scores = np.where(df[\"Margin\"] > 0, df[\"Away Score\"], df[\"Home Score\"])\n",
    "    avg_losing_score = np.floor(np.mean(losing_scores))\n",
    "    # Get simulated game data\n",
    "    massey_sim_dat = get_sim_game_dat(lsts[0], \"Massey\", avg_losing_score)\n",
    "    colley_sim_dat = get_sim_game_dat(lsts[1], \"Colley\", avg_losing_score)\n",
    "    # Store each data frame of simulated game data\n",
    "    sim_game_data = [massey_sim_dat, colley_sim_dat]\n",
    "    # Concat simulated game data into one data frame of simulated game data\n",
    "    sim_game_data = pd.concat(sim_game_data, axis = 0, sort = False)\n",
    "    # Make look like standard data frame of just game information\n",
    "    sim_game_data = sim_game_data.loc[:, [\"Home Team\", \"Away Team\", \"Home Score\", \"Away Score\", \"Margin\"]]\n",
    "    # Run the given algorithm on the simulated game data. This is known as the \"combiner method\"\n",
    "    if combiner_method == get_colley:  # If the combiner method is Colley we need Massey Matrix M\n",
    "        Massey_matrix = get_massey(sim_game_data)[0]\n",
    "        res = combiner_method(sim_game_data, Massey_matrix)\n",
    "        mat = res[0]\n",
    "        ratings = res[1]\n",
    "        # Arrange ratings properly and add Rank column\n",
    "        ratings = ratings.sort_values(by = \"Rating\", ascending = False)\n",
    "        ratings[\"Rank\"] = ratings[\"Rating\"].rank(ascending = False)\n",
    "        return mat, ratings.reset_index(drop = True)\n",
    "    else:\n",
    "        res = combiner_method(sim_game_data)\n",
    "        if len(res) > 1:  # If true then this is the Massey Method and so we need the matrix\n",
    "            mat = res[0]\n",
    "            ratings = res[1]\n",
    "            # Arrange ratings properly and add Rank column\n",
    "            ratings = ratings.sort_values(by = \"Rating\", ascending = False)\n",
    "            ratings[\"Rank\"] = ratings[\"Rating\"].rank(ascending = False)\n",
    "            return mat, ratings.reset_index(drop = True)\n",
    "        else:\n",
    "            # Arrange ratings properly and add Rank column\n",
    "            ratings = ratings.sort_values(by = \"Rating\", ascending = False)\n",
    "            ratings[\"Rank\"] = ratings[\"Rating\"].rank(ascending = False)\n",
    "            return ratings.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our 2020 tests, we had a tie in the Colley ratings between Atlanta and Carolina! Oh noooooooooo! Let's try breaking it by doing the following:\n",
    "1. Check for H2H matchup winner (if there's a winner, we break the tie and stop)\n",
    "2. Use the original combiner method ratings to break the tie\n",
    "\n",
    "In this case, if there is no H2H winner, then since the tie has arisen with Colley used as the combiner method, we will look at the original Colley ratings to break the tie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Breaks a tie by checking for H2H matchup results, and then, if there are none, selecting the top team of an original\n",
    "# rating list, i.e. a \"partial dictator\" list\n",
    "# Input: df with game info, rating list with a tie, and \"dictator\" rating list that will break the tie\n",
    "# Output: rating list with no ties\n",
    "def break_tie(df, rating_lst_tie, rating_lst_dictator):\n",
    "    # Get tied teams\n",
    "    tied_teams = rating_lst_tie.groupby(\"Rank\").filter(lambda sf: sf[\"Team\"].count() > 1)[\"Team\"].tolist()\n",
    "    team1 = tied_teams[0]\n",
    "    team2 = tied_teams[1]\n",
    "    # Get data frame of game info for tie teams\n",
    "    h2h = df[((df[\"Home Team\"] == team1) & (df[\"Away Team\"] == team2)) \n",
    "              | ((df[\"Home Team\"] == team2) & (df[\"Away Team\"] == team1))]\n",
    "    # Put # wins for each team into dict\n",
    "    num_wins = dict(h2h.groupby(\"Winner\").count()[\"Loser\"])\n",
    "    # Check for H2H winner\n",
    "    if max(num_wins.values()) - min(num_wins.values()) > 0:  # True if there is a H2H winner\n",
    "        h2h_winner = max(num_wins, key = num_wins.get)\n",
    "        h2h_loser = min(num_wins, key = num_wins.get)\n",
    "    else:  # Find H2H winner in the dictator rating list\n",
    "        tied_frame = rating_lst_dictator[rating_lst_dictator[\"Team\"].isin(tied_teams)]\n",
    "        h2h_winner = (tied_frame.loc[tied_frame[\"Rank\"] == np.min(tied_frame[\"Rank\"]), \"Team\"]).values[0]\n",
    "        h2h_loser = (tied_frame.loc[tied_frame[\"Rank\"] == np.max(tied_frame[\"Rank\"]), \"Team\"]).values[0]\n",
    "    # Change ranks in the list with the tie\n",
    "    rating_lst_tie[\"Rank\"] = np.where(rating_lst_tie[\"Team\"] == h2h_winner,\n",
    "                                      np.floor(rating_lst_tie[\"Rank\"]), \n",
    "                                      rating_lst_tie[\"Rank\"])\n",
    "    rating_lst_tie[\"Rank\"] = np.where(rating_lst_tie[\"Team\"] == h2h_loser,\n",
    "                                      np.ceil(rating_lst_tie[\"Rank\"]),\n",
    "                                      rating_lst_tie[\"Rank\"])\n",
    "    # Re-rank list\n",
    "    rating_lst_tie[\"Rank\"] = rating_lst_tie[\"Rank\"].rank(ascending = True)\n",
    "    # Return final rating list\n",
    "    return rating_lst_tie.sort_values(by = \"Rank\", ascending = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! The Panthers are ahead of the Falcons because they were ahead in `full_2020_colley_ratings`, the \"dictator\" rating list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2021 Ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need 3 weeks of data to find a unique solution to the Masey and Colley algorithms. Hence, we need some of 2020's data to help us at the beginning of the 2021 season."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preseason**: We will regress 2020's final ratings by one-third, inspired by the function $y = \\frac{1}{1.5^{w + 1}}$, which equals two-thirds when the input is zero. Hence this gives the desired regression percentage.\n",
    "\n",
    "**In Season Idea 1**: $\\text{Week} \\ w_i \\ \\text{2021 Rating} = \\frac{1}{1.5^{w_i + 1}}*\\text{2020 Rating} + (1 - (\\frac{1}{1.5^{w_i + 1}}))*\\text{2021 rating with} \\ w_i \\ \\text{2020 games replaced}$, for $w_i \\in [1, 8]$.\n",
    "\n",
    "This is a weighted average where the weight on 2020 ratings decreases exponentially. Now, to be able to still find a unique solution for our ratings, for ever week played I will replace that week's 2020 games with the corresponding week's 2021 games. For instance, after Week 1, I will remove all 2020 Week 1 games and replace them with all 2021 Week 1 games. This ensures we still have enough data to find unique solutions while also serving as its own weighting system that gives weight 0 to old 2020 games and weight 1 to new 2021 games.\n",
    "\n",
    "The post-Week 8 ratings will be the last that consider 2020 data, and so post-Week 9 we will rely on 2021 data only. Thus for half the season we get (quickly diminishing) help from 2020 data, and after Week 9, when we should have a good idea who is good and who is bad, we use 2021 data only.\n",
    "\n",
    "Note the function $y_i = \\frac{1}{1.5^{w_i + 1}}$ where $y_i$ is the weight for week i $w_i$ is nice because, for the preseason $w_0$, we effectively regress the 2020 ratings the mean by one-third, a convention used by other popular forecasters like [538](https://fivethirtyeight.com/methodology/how-our-nfl-predictions-work/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Idea 2**: Just use $\\text{Week} \\ w_i \\ \\text{2021 Rating} = \\frac{1}{1.5^{w_i + 1}}*\\text{2020 Rating} + (1 - (\\frac{1}{1.5^{w_i + 1}}))*\\text{2021 rating with} \\ {w_i} \\ \\text{early games replaced}$, for $w_i \\in [1, 8]$, ignoring the replacement idea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These ideas are fully implemented below in `do_ratings()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace_weeks() takes past game data and replaces it with corresponding new game data\n",
    "# Will be used post-Weeks 1-8\n",
    "def replace_weeks(datold, datnew):\n",
    "    to_replace_df = datold.copy()  # Don't want to modify old game data\n",
    "    #print(datold[0:33])\n",
    "    to_replace_df.loc[to_replace_df[\"Week\"].isin(datnew[\"Week\"])] = np.nan  # Sets games to replace with NaN\n",
    "    #print(to_replace_df[0:33])\n",
    "    # Check if we have more games to replace (since especially for 2020, some games were canceled by COVID)\n",
    "    num_to_concat = datnew.shape[0] - (to_replace_df.shape[0] - to_replace_df.dropna().shape[0])\n",
    "    while num_to_concat > 0: \n",
    "        print(num_to_concat)\n",
    "        to_replace_df = to_replace_df.append(pd.Series(), ignore_index = True)\n",
    "        num_to_concat -= 1\n",
    "    # Drop NaN rows and concat new 2021 data\n",
    "    replaced = pd.concat([to_replace_df.dropna(axis = 0), datnew])\n",
    "    # Clean replaced and return it\n",
    "    replaced[\"Week\"] = replaced[\"Week\"].astype('int')\n",
    "    return replaced.sort_values(by = \"Game #\", ascending = True).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a week w, an old rating and new rating, returns weighted rating according to theory above\n",
    "def get_weighted_rating(w, oldrating, newrating):\n",
    "    y = 1 / (1.5 ** (w + 1))  # The weight\n",
    "    rating = y * oldrating + (1 - y) * newrating\n",
    "    return rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rating Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Takes two data frames: one of old data and one of new data, a week, a boolean replace for\n",
    "# if we want to replace old data or not, and runs the Massey/Colling/Aggregating process\n",
    "# Returns Massey-aggregated ratings\n",
    "def do_ratings(datold, datnew, week, replace = True):\n",
    "    # Check if preseason or in season\n",
    "    if week == 0:  # True if in preseason\n",
    "        # Get standard Massey and Colley ratings\n",
    "        Mold, masseyold = get_massey(datold)\n",
    "        Cold, colleyold = get_colley(datold, Mold)\n",
    "        masseyold.to_csv(\"../data/nfl_2021/week\" + str(week) + \"/standard_massey_ratings.csv\", index = False)\n",
    "        colleyold.to_csv(\"../data/nfl_2021/week\" + str(week) + \"/standard_colley_ratings.csv\", index = False)\n",
    "    \n",
    "        # Aggregate the above ratings with Massey as dictator\n",
    "        massey_agg = aggregate_lists(datold, [masseyold, colleyold], get_massey)\n",
    "        massey_agg_ratings = massey_agg[1]\n",
    "    \n",
    "        # Check for ties\n",
    "        massey_tie = not len(massey_agg_ratings[\"Rank\"].unique()) == 32\n",
    "        print(\"Is there a tie in the Massey-combined list?\", massey_tie)\n",
    "        while massey_tie:\n",
    "            # Call break_tie()\n",
    "            massey_agg_ratings = break_tie(datold, massey_agg_ratings, masseyold)\n",
    "            # Check again for a tie\n",
    "            massey_tie = not len(massey_agg_ratings[\"Rank\"].unique()) == 32\n",
    "        massey_agg_ratings.to_csv(\"../data/nfl_2021/week\" + str(week) + \"/aggregated_massey_ratings.csv\", index = False)\n",
    "    \n",
    "        # Weight the resulting list\n",
    "        massey_agg_ratings[\"Weighted Rating\"] = get_weighted_rating(w, massey_agg_ratings[\"Rating\"], 0)\n",
    "        massey_agg_ratings[\"Weighted O Rating\"] = get_weighted_rating(w, massey_agg_ratings[\"O Rating\"], 0)\n",
    "        massey_agg_ratings[\"Weighted D Rating\"] = get_weighted_rating(w, massey_agg_ratings[\"D Rating\"], 0)\n",
    "    \n",
    "        # Rank ratings\n",
    "        massey_agg_ratings[\"Rank\"] = massey_agg_ratings[\"Weighted Rating\"].rank(ascending = False)\n",
    "        massey_agg_ratings = massey_agg_ratings.sort_values(by = \"Rank\", ascending = True).reset_index(drop = True)\n",
    "    \n",
    "    elif (week >= 1) and (week <= 8):  # True if in season and still need help from old data\n",
    "        # Get standard Massey and Colley ratings for old data\n",
    "        Mold, masseyold = get_massey(datold)\n",
    "        Cold, colleyold = get_colley(datold, Mold)\n",
    "        masseyold.to_csv(\"../data/nfl_2021/week\" + str(week) + \"/standard_massey_ratings.csv\", index = False)\n",
    "        colleyold.to_csv(\"../data/nfl_2021/week\" + str(week) + \"/standard_colley_ratings.csv\", index = False)\n",
    "    \n",
    "        # Aggregate the above ratings with Massey as dictator\n",
    "        massey_agg = aggregate_lists(datold, [masseyold, colleyold], get_massey)\n",
    "        massey_agg_ratings = massey_agg[1]\n",
    "    \n",
    "        # Check for ties\n",
    "        massey_tie = not len(massey_agg_ratings[\"Rank\"].unique()) == 32\n",
    "        print(\"Is there a tie in the Massey-combined list?\", massey_tie)\n",
    "        while massey_tie:\n",
    "            # Call break_tie()\n",
    "            massey_agg_ratings = break_tie(datold, massey_agg_ratings, masseyold)\n",
    "            # Check again for a tie\n",
    "            massey_tie = not len(massey_agg_ratings[\"Rank\"].unique()) == 32\n",
    "        massey_agg_ratings.to_csv(\"../data/nfl_2021/week\" + str(w) + \"/aggregated_massey_ratings.csv\", index = False)\n",
    "        \n",
    "        # Combine old data with new data\n",
    "        if replace:  # TRUE if we want to replace when we combine\n",
    "            datold_combined = replace_weeks(datold, datnew)\n",
    "        else:  # If we just want to combine\n",
    "            datold_combined = pd.concat([datold, datnew], axis = 0)\n",
    "    \n",
    "        # Get Massey and Colley with combined data\n",
    "        Mold_combined, masseyold_combined = get_massey(datold_combined)\n",
    "        Cold_combined, colleyold_combined = get_colley(datold_combined, Mold_combined)\n",
    "        masseyold_combined.to_csv(\"../data/nfl_2021/week\" + str(week) + \"/combined_massey_ratings.csv\", index = False)\n",
    "        colleyold_combined.to_csv(\"../data/nfl_2021/week\" + str(week) + \"/combined_colley_ratings.csv\", index = False)\n",
    "    \n",
    "        # Aggregate the above ratings with Massey as dictator\n",
    "        massey_agg_combined = aggregate_lists(datold_combined, [masseyold_combined, colleyold_combined], get_massey)\n",
    "        massey_agg_combined_ratings = massey_agg_combined[1]\n",
    "    \n",
    "        # Check for ties\n",
    "        massey_combined_tie = not len(massey_agg_combined_ratings[\"Rank\"].unique()) == 32\n",
    "        print(\"Is there a tie in the Massey-combined combined list?\", massey_combined_tie)\n",
    "        while massey_combined_tie:\n",
    "            # Call break_tie()\n",
    "            massey_agg_combined_ratings = break_tie(datold_combined, massey_agg_combined_ratings, masseyold_combined)\n",
    "            # Check again for a tie\n",
    "            massey_combined_tie = not len(massey_agg_combined_ratings[\"Rank\"].unique()) == 32\n",
    "        massey_agg_combined_ratings.to_csv(\"../data/nfl_2021/week\" + str(week) + \"/aggregated_combined_massey_ratings.csv\", index = False)\n",
    "    \n",
    "        # Merge old ratings with new, replaced ratings\n",
    "        massey_agg_ratings = massey_agg_ratings.merge(massey_agg_combined_ratings, on = \"Team\", suffixes = (\"_old\", \"_new\"))\n",
    "    \n",
    "        # Get weighted ratings\n",
    "        massey_agg_ratings[\"Weighted Rating\"] = massey_agg_ratings.apply(lambda x: get_weighted_rating(w, \n",
    "                                                                                               x[\"Rating_old\"], \n",
    "                                                                                               x[\"Rating_new\"]), \n",
    "                                                                         axis = 1)\n",
    "        massey_agg_ratings[\"Weighted O Rating\"] = massey_agg_ratings.apply(lambda x: get_weighted_rating(w, \n",
    "                                                                                               x[\"O Rating_old\"], \n",
    "                                                                                               x[\"O Rating_new\"]), \n",
    "                                                                         axis = 1)\n",
    "        massey_agg_ratings[\"Weighted D Rating\"] = massey_agg_ratings.apply(lambda x: get_weighted_rating(w, \n",
    "                                                                                               x[\"D Rating_old\"], \n",
    "                                                                                               x[\"D Rating_new\"]), \n",
    "                                                                         axis = 1)\n",
    "        # Rank ratings\n",
    "        massey_agg_ratings[\"Rank\"] = massey_agg_ratings[\"Weighted Rating\"].rank(ascending = False)\n",
    "        massey_agg_ratings = massey_agg_ratings.sort_values(by = \"Rank\", ascending = True).reset_index(drop = True)\n",
    "    \n",
    "    else:  # True if through 9 weeks or more\n",
    "        # Get standard Massey and Colley ratings for new data\n",
    "        Mnew, masseynew = get_massey(datnew)\n",
    "        Cnew, colleynew = get_colley(datnew, Mnew)\n",
    "        masseynew.to_csv(\"../data/nfl_2021/week\" + str(week) + \"/standard_massey_ratings.csv\", index = False)\n",
    "        colleynew.to_csv(\"../data/nfl_2021/week\" + str(week) + \"/standard_colley_ratings.csv\", index = False)\n",
    "    \n",
    "        # Aggregate the above ratings with Massey as dictator\n",
    "        massey_agg = aggregate_lists(datnew, [masseynew, colleynew], get_massey)\n",
    "        massey_agg_ratings = massey_agg[1]\n",
    "    \n",
    "        # Check for ties\n",
    "        massey_tie = not len(massey_agg_ratings[\"Rank\"].unique()) == 32\n",
    "        print(\"Is there a tie in the Massey-combined list?\", massey_tie)\n",
    "        while massey_tie:\n",
    "            # Call break_tie()\n",
    "            massey_agg_ratings = break_tie(datnew, massey_agg_ratings, masseynew)\n",
    "            # Check again for a tie\n",
    "            massey_tie = not len(massey_agg_ratings[\"Rank\"].unique()) == 32\n",
    "        massey_agg_ratings.to_csv(\"../data/nfl_2021/week\" + str(week) + \"/aggregated_massey_ratings.csv\", index = False)\n",
    "\n",
    "    # Write final ratings to csv\n",
    "    massey_agg_ratings.to_csv(\"../data/nfl_2021/week\" + str(week) + \"/final_massey_ratings.csv\", index = False) \n",
    "\n",
    "    # Return ratings!\n",
    "    return massey_agg_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is there a tie in the Massey-combined list? False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jakesingleton/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:61: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is there a tie in the Massey-combined combined list? False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating_old</th>\n",
       "      <th>O Rating_old</th>\n",
       "      <th>D Rating_old</th>\n",
       "      <th>Rank_old</th>\n",
       "      <th>Rating_new</th>\n",
       "      <th>O Rating_new</th>\n",
       "      <th>D Rating_new</th>\n",
       "      <th>Rank_new</th>\n",
       "      <th>Weighted Rating</th>\n",
       "      <th>Weighted O Rating</th>\n",
       "      <th>Weighted D Rating</th>\n",
       "      <th>Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Tampa Bay Buccaneers</td>\n",
       "      <td>12.015625</td>\n",
       "      <td>19.658619</td>\n",
       "      <td>-7.642994</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.562500</td>\n",
       "      <td>19.204637</td>\n",
       "      <td>-7.642137</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.763889</td>\n",
       "      <td>19.406407</td>\n",
       "      <td>-7.642518</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>New Orleans Saints</td>\n",
       "      <td>10.359375</td>\n",
       "      <td>18.080494</td>\n",
       "      <td>-7.721119</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.359375</td>\n",
       "      <td>19.044741</td>\n",
       "      <td>-7.685366</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.914931</td>\n",
       "      <td>18.616187</td>\n",
       "      <td>-7.701256</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Kansas City Chiefs</td>\n",
       "      <td>10.859375</td>\n",
       "      <td>18.547161</td>\n",
       "      <td>-7.687786</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.796875</td>\n",
       "      <td>18.480158</td>\n",
       "      <td>-7.683283</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.824653</td>\n",
       "      <td>18.509937</td>\n",
       "      <td>-7.685284</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Buffalo Bills</td>\n",
       "      <td>10.703125</td>\n",
       "      <td>18.369036</td>\n",
       "      <td>-7.665911</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.687500</td>\n",
       "      <td>18.350470</td>\n",
       "      <td>-7.662970</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.694444</td>\n",
       "      <td>18.358722</td>\n",
       "      <td>-7.664277</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Green Bay Packers</td>\n",
       "      <td>10.234375</td>\n",
       "      <td>17.917994</td>\n",
       "      <td>-7.683619</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.109375</td>\n",
       "      <td>15.986408</td>\n",
       "      <td>-7.877033</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.053819</td>\n",
       "      <td>16.844891</td>\n",
       "      <td>-7.791071</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Pittsburgh Steelers</td>\n",
       "      <td>6.984375</td>\n",
       "      <td>15.092994</td>\n",
       "      <td>-8.108619</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.734375</td>\n",
       "      <td>15.732241</td>\n",
       "      <td>-7.997866</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.401042</td>\n",
       "      <td>15.448131</td>\n",
       "      <td>-8.047090</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Seattle Seahawks</td>\n",
       "      <td>7.015625</td>\n",
       "      <td>15.091952</td>\n",
       "      <td>-8.076327</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.562500</td>\n",
       "      <td>15.521304</td>\n",
       "      <td>-7.958804</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.319444</td>\n",
       "      <td>15.330481</td>\n",
       "      <td>-8.011036</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Baltimore Ravens</td>\n",
       "      <td>7.765625</td>\n",
       "      <td>15.766952</td>\n",
       "      <td>-8.001327</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.343750</td>\n",
       "      <td>14.628595</td>\n",
       "      <td>-8.284845</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.975694</td>\n",
       "      <td>15.134532</td>\n",
       "      <td>-8.158837</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Los Angeles Rams</td>\n",
       "      <td>5.187500</td>\n",
       "      <td>13.752890</td>\n",
       "      <td>-8.565390</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.781250</td>\n",
       "      <td>14.930679</td>\n",
       "      <td>-8.149429</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.072917</td>\n",
       "      <td>14.407217</td>\n",
       "      <td>-8.334300</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Miami Dolphins</td>\n",
       "      <td>3.578125</td>\n",
       "      <td>12.539869</td>\n",
       "      <td>-8.961744</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.765625</td>\n",
       "      <td>14.147866</td>\n",
       "      <td>-8.382241</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.793403</td>\n",
       "      <td>13.433201</td>\n",
       "      <td>-8.639798</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Tennessee Titans</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>12.859140</td>\n",
       "      <td>-8.859140</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.578125</td>\n",
       "      <td>11.320783</td>\n",
       "      <td>-9.742658</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.654514</td>\n",
       "      <td>12.004497</td>\n",
       "      <td>-9.349983</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Indianapolis Colts</td>\n",
       "      <td>3.109375</td>\n",
       "      <td>12.255494</td>\n",
       "      <td>-9.146119</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.093750</td>\n",
       "      <td>11.653595</td>\n",
       "      <td>-9.559845</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.545139</td>\n",
       "      <td>11.921106</td>\n",
       "      <td>-9.375967</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Cleveland Browns</td>\n",
       "      <td>2.953125</td>\n",
       "      <td>12.427369</td>\n",
       "      <td>-9.474244</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.140625</td>\n",
       "      <td>11.768700</td>\n",
       "      <td>-9.628075</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.501736</td>\n",
       "      <td>12.061442</td>\n",
       "      <td>-9.559705</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>Arizona Cardinals</td>\n",
       "      <td>1.406250</td>\n",
       "      <td>11.262265</td>\n",
       "      <td>-9.856015</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.796875</td>\n",
       "      <td>12.196825</td>\n",
       "      <td>-9.399950</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.178819</td>\n",
       "      <td>11.781465</td>\n",
       "      <td>-9.602645</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>Las Vegas Raiders</td>\n",
       "      <td>0.359375</td>\n",
       "      <td>10.747161</td>\n",
       "      <td>-10.387786</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.796875</td>\n",
       "      <td>11.513491</td>\n",
       "      <td>-9.716616</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.157986</td>\n",
       "      <td>11.172900</td>\n",
       "      <td>-10.014914</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>New England Patriots</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>10.585181</td>\n",
       "      <td>-10.366431</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-0.531250</td>\n",
       "      <td>10.141095</td>\n",
       "      <td>-10.672345</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-0.197917</td>\n",
       "      <td>10.338467</td>\n",
       "      <td>-10.536384</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>San Francisco 49ers</td>\n",
       "      <td>-1.406250</td>\n",
       "      <td>9.856015</td>\n",
       "      <td>-11.262265</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>10.460887</td>\n",
       "      <td>-10.585887</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-0.694444</td>\n",
       "      <td>10.192055</td>\n",
       "      <td>-10.886499</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>Chicago Bears</td>\n",
       "      <td>-0.140625</td>\n",
       "      <td>10.397161</td>\n",
       "      <td>-10.537786</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-2.281250</td>\n",
       "      <td>9.399429</td>\n",
       "      <td>-11.680679</td>\n",
       "      <td>19.0</td>\n",
       "      <td>-1.329861</td>\n",
       "      <td>9.842865</td>\n",
       "      <td>-11.172726</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>Los Angeles Chargers</td>\n",
       "      <td>-2.125000</td>\n",
       "      <td>9.563306</td>\n",
       "      <td>-11.688306</td>\n",
       "      <td>19.0</td>\n",
       "      <td>-0.859375</td>\n",
       "      <td>10.102033</td>\n",
       "      <td>-10.961408</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-1.421875</td>\n",
       "      <td>9.862599</td>\n",
       "      <td>-11.284474</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>Washington Football Team</td>\n",
       "      <td>-3.171875</td>\n",
       "      <td>9.131536</td>\n",
       "      <td>-12.303411</td>\n",
       "      <td>21.0</td>\n",
       "      <td>-3.546875</td>\n",
       "      <td>8.991616</td>\n",
       "      <td>-12.538491</td>\n",
       "      <td>21.0</td>\n",
       "      <td>-3.380208</td>\n",
       "      <td>9.053803</td>\n",
       "      <td>-12.434011</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>Minnesota Vikings</td>\n",
       "      <td>-2.218750</td>\n",
       "      <td>9.466431</td>\n",
       "      <td>-11.685181</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-4.375000</td>\n",
       "      <td>8.719220</td>\n",
       "      <td>-13.094220</td>\n",
       "      <td>23.0</td>\n",
       "      <td>-3.416667</td>\n",
       "      <td>9.051314</td>\n",
       "      <td>-12.467981</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>Carolina Panthers</td>\n",
       "      <td>-4.171875</td>\n",
       "      <td>8.848202</td>\n",
       "      <td>-13.020077</td>\n",
       "      <td>22.0</td>\n",
       "      <td>-2.859375</td>\n",
       "      <td>9.185366</td>\n",
       "      <td>-12.044741</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-3.442708</td>\n",
       "      <td>9.035516</td>\n",
       "      <td>-12.478224</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>Denver Broncos</td>\n",
       "      <td>-5.093750</td>\n",
       "      <td>8.662265</td>\n",
       "      <td>-13.756015</td>\n",
       "      <td>23.0</td>\n",
       "      <td>-3.609375</td>\n",
       "      <td>9.127033</td>\n",
       "      <td>-12.736408</td>\n",
       "      <td>22.0</td>\n",
       "      <td>-4.269097</td>\n",
       "      <td>8.920469</td>\n",
       "      <td>-13.189567</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>Atlanta Falcons</td>\n",
       "      <td>-5.296875</td>\n",
       "      <td>8.919036</td>\n",
       "      <td>-14.215911</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-6.187500</td>\n",
       "      <td>8.446304</td>\n",
       "      <td>-14.633804</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-5.791667</td>\n",
       "      <td>8.656407</td>\n",
       "      <td>-14.448073</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>New York Giants</td>\n",
       "      <td>-5.343750</td>\n",
       "      <td>8.470598</td>\n",
       "      <td>-13.814348</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-6.468750</td>\n",
       "      <td>8.222345</td>\n",
       "      <td>-14.691095</td>\n",
       "      <td>26.0</td>\n",
       "      <td>-5.968750</td>\n",
       "      <td>8.332680</td>\n",
       "      <td>-14.301430</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>Dallas Cowboys</td>\n",
       "      <td>-6.718750</td>\n",
       "      <td>8.149765</td>\n",
       "      <td>-14.868515</td>\n",
       "      <td>26.0</td>\n",
       "      <td>-6.656250</td>\n",
       "      <td>8.145262</td>\n",
       "      <td>-14.801512</td>\n",
       "      <td>27.0</td>\n",
       "      <td>-6.684028</td>\n",
       "      <td>8.147263</td>\n",
       "      <td>-14.831291</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>Philadelphia Eagles</td>\n",
       "      <td>-8.859375</td>\n",
       "      <td>7.887786</td>\n",
       "      <td>-16.747161</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-6.375000</td>\n",
       "      <td>8.269220</td>\n",
       "      <td>-14.644220</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-7.479167</td>\n",
       "      <td>8.099694</td>\n",
       "      <td>-15.578861</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>Cincinnati Bengals</td>\n",
       "      <td>-8.375000</td>\n",
       "      <td>7.938306</td>\n",
       "      <td>-16.313306</td>\n",
       "      <td>27.0</td>\n",
       "      <td>-7.156250</td>\n",
       "      <td>8.195262</td>\n",
       "      <td>-15.351512</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-7.697917</td>\n",
       "      <td>8.081060</td>\n",
       "      <td>-15.778976</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>Houston Texans</td>\n",
       "      <td>-8.843750</td>\n",
       "      <td>7.837265</td>\n",
       "      <td>-16.681015</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-9.453125</td>\n",
       "      <td>7.821825</td>\n",
       "      <td>-17.274950</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-9.182292</td>\n",
       "      <td>7.828687</td>\n",
       "      <td>-17.010979</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>Detroit Lions</td>\n",
       "      <td>-8.734375</td>\n",
       "      <td>7.866952</td>\n",
       "      <td>-16.601327</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-10.156250</td>\n",
       "      <td>7.745262</td>\n",
       "      <td>-17.901512</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-9.524306</td>\n",
       "      <td>7.799347</td>\n",
       "      <td>-17.323652</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>New York Jets</td>\n",
       "      <td>-12.843750</td>\n",
       "      <td>7.637265</td>\n",
       "      <td>-20.481015</td>\n",
       "      <td>31.0</td>\n",
       "      <td>-12.453125</td>\n",
       "      <td>7.671825</td>\n",
       "      <td>-20.124950</td>\n",
       "      <td>31.0</td>\n",
       "      <td>-12.626736</td>\n",
       "      <td>7.656465</td>\n",
       "      <td>-20.283201</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>Jacksonville Jaguars</td>\n",
       "      <td>-13.406250</td>\n",
       "      <td>7.639348</td>\n",
       "      <td>-21.045598</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-14.015625</td>\n",
       "      <td>7.673908</td>\n",
       "      <td>-21.689533</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-13.744792</td>\n",
       "      <td>7.658548</td>\n",
       "      <td>-21.403340</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Team  Rating_old  O Rating_old  D Rating_old  \\\n",
       "0       Tampa Bay Buccaneers   12.015625     19.658619     -7.642994   \n",
       "1         New Orleans Saints   10.359375     18.080494     -7.721119   \n",
       "2         Kansas City Chiefs   10.859375     18.547161     -7.687786   \n",
       "3              Buffalo Bills   10.703125     18.369036     -7.665911   \n",
       "4          Green Bay Packers   10.234375     17.917994     -7.683619   \n",
       "5        Pittsburgh Steelers    6.984375     15.092994     -8.108619   \n",
       "6           Seattle Seahawks    7.015625     15.091952     -8.076327   \n",
       "7           Baltimore Ravens    7.765625     15.766952     -8.001327   \n",
       "8           Los Angeles Rams    5.187500     13.752890     -8.565390   \n",
       "9             Miami Dolphins    3.578125     12.539869     -8.961744   \n",
       "10          Tennessee Titans    4.000000     12.859140     -8.859140   \n",
       "11        Indianapolis Colts    3.109375     12.255494     -9.146119   \n",
       "12          Cleveland Browns    2.953125     12.427369     -9.474244   \n",
       "13         Arizona Cardinals    1.406250     11.262265     -9.856015   \n",
       "14         Las Vegas Raiders    0.359375     10.747161    -10.387786   \n",
       "15      New England Patriots    0.218750     10.585181    -10.366431   \n",
       "16       San Francisco 49ers   -1.406250      9.856015    -11.262265   \n",
       "17             Chicago Bears   -0.140625     10.397161    -10.537786   \n",
       "18      Los Angeles Chargers   -2.125000      9.563306    -11.688306   \n",
       "19  Washington Football Team   -3.171875      9.131536    -12.303411   \n",
       "20         Minnesota Vikings   -2.218750      9.466431    -11.685181   \n",
       "21         Carolina Panthers   -4.171875      8.848202    -13.020077   \n",
       "22            Denver Broncos   -5.093750      8.662265    -13.756015   \n",
       "23           Atlanta Falcons   -5.296875      8.919036    -14.215911   \n",
       "24           New York Giants   -5.343750      8.470598    -13.814348   \n",
       "25            Dallas Cowboys   -6.718750      8.149765    -14.868515   \n",
       "26       Philadelphia Eagles   -8.859375      7.887786    -16.747161   \n",
       "27        Cincinnati Bengals   -8.375000      7.938306    -16.313306   \n",
       "28            Houston Texans   -8.843750      7.837265    -16.681015   \n",
       "29             Detroit Lions   -8.734375      7.866952    -16.601327   \n",
       "30             New York Jets  -12.843750      7.637265    -20.481015   \n",
       "31      Jacksonville Jaguars  -13.406250      7.639348    -21.045598   \n",
       "\n",
       "    Rank_old  Rating_new  O Rating_new  D Rating_new  Rank_new  \\\n",
       "0        1.0   11.562500     19.204637     -7.642137       1.0   \n",
       "1        4.0   11.359375     19.044741     -7.685366       2.0   \n",
       "2        2.0   10.796875     18.480158     -7.683283       3.0   \n",
       "3        3.0   10.687500     18.350470     -7.662970       4.0   \n",
       "4        5.0    8.109375     15.986408     -7.877033       5.0   \n",
       "5        8.0    7.734375     15.732241     -7.997866       6.0   \n",
       "6        7.0    7.562500     15.521304     -7.958804       7.0   \n",
       "7        6.0    6.343750     14.628595     -8.284845       9.0   \n",
       "8        9.0    6.781250     14.930679     -8.149429       8.0   \n",
       "9       11.0    5.765625     14.147866     -8.382241      10.0   \n",
       "10      10.0    1.578125     11.320783     -9.742658      15.0   \n",
       "11      12.0    2.093750     11.653595     -9.559845      13.0   \n",
       "12      13.0    2.140625     11.768700     -9.628075      12.0   \n",
       "13      14.0    2.796875     12.196825     -9.399950      11.0   \n",
       "14      15.0    1.796875     11.513491     -9.716616      14.0   \n",
       "15      16.0   -0.531250     10.141095    -10.672345      17.0   \n",
       "16      18.0   -0.125000     10.460887    -10.585887      16.0   \n",
       "17      17.0   -2.281250      9.399429    -11.680679      19.0   \n",
       "18      19.0   -0.859375     10.102033    -10.961408      18.0   \n",
       "19      21.0   -3.546875      8.991616    -12.538491      21.0   \n",
       "20      20.0   -4.375000      8.719220    -13.094220      23.0   \n",
       "21      22.0   -2.859375      9.185366    -12.044741      20.0   \n",
       "22      23.0   -3.609375      9.127033    -12.736408      22.0   \n",
       "23      24.0   -6.187500      8.446304    -14.633804      24.0   \n",
       "24      25.0   -6.468750      8.222345    -14.691095      26.0   \n",
       "25      26.0   -6.656250      8.145262    -14.801512      27.0   \n",
       "26      30.0   -6.375000      8.269220    -14.644220      25.0   \n",
       "27      27.0   -7.156250      8.195262    -15.351512      28.0   \n",
       "28      29.0   -9.453125      7.821825    -17.274950      29.0   \n",
       "29      28.0  -10.156250      7.745262    -17.901512      30.0   \n",
       "30      31.0  -12.453125      7.671825    -20.124950      31.0   \n",
       "31      32.0  -14.015625      7.673908    -21.689533      32.0   \n",
       "\n",
       "    Weighted Rating  Weighted O Rating  Weighted D Rating  Rank  \n",
       "0         11.763889          19.406407          -7.642518   1.0  \n",
       "1         10.914931          18.616187          -7.701256   2.0  \n",
       "2         10.824653          18.509937          -7.685284   3.0  \n",
       "3         10.694444          18.358722          -7.664277   4.0  \n",
       "4          9.053819          16.844891          -7.791071   5.0  \n",
       "5          7.401042          15.448131          -8.047090   6.0  \n",
       "6          7.319444          15.330481          -8.011036   7.0  \n",
       "7          6.975694          15.134532          -8.158837   8.0  \n",
       "8          6.072917          14.407217          -8.334300   9.0  \n",
       "9          4.793403          13.433201          -8.639798  10.0  \n",
       "10         2.654514          12.004497          -9.349983  11.0  \n",
       "11         2.545139          11.921106          -9.375967  12.0  \n",
       "12         2.501736          12.061442          -9.559705  13.0  \n",
       "13         2.178819          11.781465          -9.602645  14.0  \n",
       "14         1.157986          11.172900         -10.014914  15.0  \n",
       "15        -0.197917          10.338467         -10.536384  16.0  \n",
       "16        -0.694444          10.192055         -10.886499  17.0  \n",
       "17        -1.329861           9.842865         -11.172726  18.0  \n",
       "18        -1.421875           9.862599         -11.284474  19.0  \n",
       "19        -3.380208           9.053803         -12.434011  20.0  \n",
       "20        -3.416667           9.051314         -12.467981  21.0  \n",
       "21        -3.442708           9.035516         -12.478224  22.0  \n",
       "22        -4.269097           8.920469         -13.189567  23.0  \n",
       "23        -5.791667           8.656407         -14.448073  24.0  \n",
       "24        -5.968750           8.332680         -14.301430  25.0  \n",
       "25        -6.684028           8.147263         -14.831291  26.0  \n",
       "26        -7.479167           8.099694         -15.578861  27.0  \n",
       "27        -7.697917           8.081060         -15.778976  28.0  \n",
       "28        -9.182292           7.828687         -17.010979  29.0  \n",
       "29        -9.524306           7.799347         -17.323652  30.0  \n",
       "30       -12.626736           7.656465         -20.283201  31.0  \n",
       "31       -13.744792           7.658548         -21.403340  32.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rate!\n",
    "\n",
    "## CHANGE AS NECESSARY (It is preseason now)\n",
    "\n",
    "# The data\n",
    "datold = load_data(2020)\n",
    "datnew = load_data(2021)\n",
    "\n",
    "# The week\n",
    "w = 1  # The week\n",
    "\n",
    "# Whether to replace\n",
    "replace = False\n",
    "\n",
    "final_ratings = do_ratings(datold, datnew, w, replace)\n",
    "final_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How did our ratings do?"
   ]
  }
 ],
 "metadata": {
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
